{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time, sleep\n",
    "from datetime import datetime\n",
    "\n",
    "import pyautogui\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_needle_img = 'dark_kills_counter_skull_icon.jpg'\n",
    "dark_needle_img_2 = 'dark_kills_counter_skull_icon_2.jpg'\n",
    "pr_needle_img = 'players_remaining_icon.png'\n",
    "\n",
    "n_kills_crop = (136, 0, 174, 28)  # 28x28 crop: (139, 0, 167, 28)\n",
    "n_players_remaining_crop = (84, 0, 122, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_screenshot(out_route=False):\n",
    "    \"\"\"\n",
    "    return 1280x720p, bgr -> grayscale screenshot\n",
    "    \"\"\"\n",
    "    # capture screenshot & resize to 720p\n",
    "    screenshot = pyautogui.screenshot() \n",
    "    screenshot = screenshot.resize((1280, 720))\n",
    "\n",
    "    grayscale = ImageOps.grayscale(screenshot)  # want to switch this to subtracting the mean\n",
    "\n",
    "    # translate colors to opencv (why/is this necessary? w/ grayscale already done?)\n",
    "    screenshot = cv.cvtColor(np.array(grayscale), cv.COLOR_RGB2BGR)\n",
    "\n",
    "    if out_route:\n",
    "        Image.fromarray(screenshot).save(out_route)\n",
    "\n",
    "    return screenshot\n",
    "\n",
    "\n",
    "def record_numbers(numbers, file_path):\n",
    "    existing_df = pd.read_csv(file_path)\n",
    "\n",
    "    temp_df = pd.DataFrame(numbers)\n",
    "    temp_df.columns = existing_df.columns\n",
    "\n",
    "    new_df = pd.concat([existing_df, temp_df], axis=0)\n",
    "    new_df.to_csv(file_path, index=False)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numbers():    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.datasets = {'28x28' : 'numbers.csv', '38x28' : 'digits_only_numbers.csv'}\n",
    "        self.update_df()\n",
    "        \n",
    "        self.IMG_SIZE = 50\n",
    "\n",
    "        self.icons_dir = 'media/icons/'\n",
    "        self.output_dir = 'media/test_record_kills_and_players_remaining/'\n",
    "        \n",
    "        self.top_left = None\n",
    "        self.trusted_top_left = None\n",
    "        self.top_left_pr_icon = None\n",
    "        \n",
    "        self.n_save_errors = 0\n",
    "        self.n_pred_errors = 0\n",
    "   \n",
    "    def load_image_arrays(self):\n",
    "        \"\"\"\n",
    "        load & resize image arrays\n",
    "        \n",
    "        returns list of 2D np.arrays sized (self.IMG_SIZE, self.IMG_SIZE) \n",
    "            > default: (50, 50)\n",
    "        \n",
    "        currently supports (38, 28) and (28, 28) sized inputs\n",
    "        \"\"\"\n",
    "        file_paths = self.df['file_path'].values\n",
    "        image_arrays = []\n",
    "        for path in file_paths:\n",
    "            base_size = Image.open(path).size\n",
    "            if base_size == (38, 28):\n",
    "                img = cv.imread(path, cv.IMREAD_GRAYSCALE)  # single channel\n",
    "                img = Image.fromarray(img).crop((0, 0-5, 38, 28+5))  # 38x28 > 38x38\n",
    "                img = cv.resize(np.array(img), (self.IMG_SIZE, self.IMG_SIZE))  # 50x50\n",
    "                image_arrays.append(img)\n",
    "            elif base_size == (28, 28):\n",
    "                img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "                img = Image.fromarray(img).crop((0-3, 0-5, 28+7, 28+5))  # 28x28 > 38x38\n",
    "                img = cv.resize(np.array(img), (self.IMG_SIZE, self.IMG_SIZE))  # 50x50\n",
    "                image_arrays.append(img)\n",
    "            else:\n",
    "                raise Exception(f'\\nerror: unknown size | {base_size}')\n",
    "        image_labels = self.df['numbers'].values\n",
    "        return image_arrays, image_labels\n",
    "    \n",
    "    def train_knn(self, train_data, labels, n_neighbors=1):\n",
    "        \"\"\"\n",
    "        Train simple KNN model to predict digits\n",
    "        \n",
    "        inputs \n",
    "        -----\n",
    "        >> train_data\n",
    "            > list of unflattend np arrays\n",
    "        >> labels\n",
    "            > list of target (y) values\n",
    "        >> n_neighbors\n",
    "            > number of neighbors (K) for KNN\n",
    "        \"\"\"\n",
    "        X = [img.flatten() for img in train_data]\n",
    "        y = labels\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        \n",
    "        knn.fit(X, y)\n",
    "        \n",
    "        return knn\n",
    "    \n",
    "    def record_livestream(self, model, n_loops=420):\n",
    "        \"\"\"\n",
    "        record {n_loops} from displayed Twitch livestream\n",
    "        \n",
    "        inputs\n",
    "        ------\n",
    "        \n",
    "        model\n",
    "        >> ml/dl model to make predictions on livestream captures\n",
    "            > currently KNN only\n",
    "        \n",
    "        n_loops\n",
    "        >> number of loops to run\n",
    "            > default == 420\n",
    "            > recent run of 10**4 loops took ~40 minutes\n",
    "            > (recommended) max == 10**7\n",
    "        \"\"\"\n",
    "        dark_needle_icon = cv.imread(f'{self.icons_dir}{dark_needle_img}', cv.IMREAD_UNCHANGED)\n",
    "        \n",
    "        dark_needle_icon_2 = cv.imread(f'{self.icons_dir}{dark_needle_img_2}', cv.IMREAD_UNCHANGED)\n",
    "        \n",
    "        players_remaining_icon = cv.imread(f'{self.icons_dir}{pr_needle_img}', cv.IMREAD_GRAYSCALE)\n",
    "        players_remaining_icon = cv.cvtColor(players_remaining_icon, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        temp_top_right_numbers_stash = []\n",
    "        \n",
    "        for _ in range(n_loops):\n",
    "            if _ < 10:\n",
    "                loop = f'loop_000000{_}'\n",
    "            elif 10 <= _ < 10**2:\n",
    "                loop = f'loop_00000{_}'\n",
    "            elif 10**2 <= _ < 10**3:\n",
    "                loop = f'loop_0000{_}'\n",
    "            elif 10**3 <= _ < 10**4:\n",
    "                loop = f'loop_000{_}'\n",
    "            elif 10**4 <= _ < 10**5:\n",
    "                loop = f'loop_00{_}'\n",
    "            elif 10**5 <= _ < 10**6:\n",
    "                loop = f'loop_0{_}'\n",
    "            else:\n",
    "                loop = f'loop_{_}'\n",
    "\n",
    "            # capture & save greyscaled bgr screenshot (1280, 720)\n",
    "            screenshot = capture_screenshot(out_route=f'{self.output_dir}og_screenshot/{loop}.jpg')\n",
    "            record_time = str(datetime.now())\n",
    "\n",
    "            # crop top (25%) right corner of the screenshot\n",
    "            top_right_numbers_screenshot = Image.fromarray(screenshot.copy())\n",
    "            top_right_numbers_screenshot = top_right_numbers_screenshot.crop((int(1280*0.75), 0, 1280, int(720*.25)))\n",
    "            top_right_numbers_screenshot = np.array(top_right_numbers_screenshot)\n",
    "\n",
    "            # look for n_kills skull icons\n",
    "            for needle_img in [dark_needle_icon_2]:  # dark_needle_icon\n",
    "                result = cv.matchTemplate(top_right_numbers_screenshot, needle_img, cv.TM_CCOEFF_NORMED)\n",
    "\n",
    "                min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "\n",
    "                threshold = 0.7\n",
    "                # do we have a satasfactory match?\n",
    "                if max_val >= threshold:\n",
    "                    \n",
    "                    needle_w = needle_img.shape[1]\n",
    "                    if needle_w < 18:\n",
    "                        print(f'needle_w=={needle_w}, adding 5')\n",
    "                        needle_w += 5\n",
    "                    needle_h = needle_img.shape[0]\n",
    "\n",
    "                    # tag top left corner, add width & height to find bottom right corner of icon\n",
    "                    top_left = max_loc \n",
    "                    bottom_right = (top_left[0] + (needle_w) - 5, top_left[1] + needle_h)\n",
    "\n",
    "                    # are we within logical area?\n",
    "                    if (top_left[0] > 120) and (90 > top_left[1] > 10):\n",
    "                        self.top_left = top_left\n",
    "                        self.bottom_right = bottom_right\n",
    "\n",
    "                        # black out kill skull icon\n",
    "                        cv.rectangle(top_right_numbers_screenshot, top_left, bottom_right, color=(0, 0, 0), thickness=-1)\n",
    "\n",
    "                # no, fell short of threshold, so go back to the last logical area we had\n",
    "                else:\n",
    "                    if self.trusted_top_left is not None:\n",
    "                        top_left = self.trusted_top_left\n",
    "                    else:\n",
    "                        top_left = self.top_left\n",
    "                    # have we gotten a top left yet?\n",
    "                    if top_left is not None:\n",
    "                        # are we within logical area?\n",
    "                        if (top_left[0] > 120) and (90 > top_left[1] > 10):\n",
    "                            bottom_right = self.bottom_right\n",
    "                            # black out kill skull icon\n",
    "                            cv.rectangle(top_right_numbers_screenshot, top_left, bottom_right, color=(0, 0, 0), thickness=-1)\n",
    "\n",
    "            # do we have a top left?\n",
    "            if top_left is not None:\n",
    "\n",
    "                # correct bottom right and expand left to just grab all linearly alligned numbers at once\n",
    "                full_bottom_right = (top_left[0] + (needle_w * 2), top_left[1] + needle_h)\n",
    "                full_top_left = tuple([top_left[0]-125, top_left[1]]) \n",
    "\n",
    "                # crop full top right numbers bar\n",
    "                top_right_numbers_screenshot_2 = top_right_numbers_screenshot[full_top_left[1]:full_bottom_right[1], \n",
    "                                                                              full_top_left[0]:full_bottom_right[0]]\n",
    "                # make sure we still have a screenshot\n",
    "                if top_right_numbers_screenshot_2.size != 0:\n",
    "                    top_right_numbers_screenshot = top_right_numbers_screenshot_2\n",
    "                    self.trusted_top_left = self.top_left\n",
    "\n",
    "                    # look for players remaining icon\n",
    "                    for needle_img_2 in [players_remaining_icon]: \n",
    "                        try:\n",
    "                            result_2 = cv.matchTemplate(top_right_numbers_screenshot, needle_img_2, cv.TM_CCOEFF_NORMED)\n",
    "                            min_val_2, max_val_2, min_loc_2, max_loc_2 = cv.minMaxLoc(result_2)\n",
    "\n",
    "                            threshold_2 = 0.8\n",
    "                            needle_2_w = needle_img_2.shape[1]\n",
    "                            needle_2_h = needle_img_2.shape[0] + 10\n",
    "                            \n",
    "                            # do we have a satasfactory match?\n",
    "                            if max_val_2 >= threshold_2:\n",
    "\n",
    "                                # tag top left corner, add width & height to find bottom right corner\n",
    "                                top_left_2 = max_loc_2  # want rectangle\n",
    "                                bottom_right_2 = (top_left_2[0] + (needle_2_w) - 5, top_left_2[1] + needle_2_h)\n",
    "                                \n",
    "                                self.top_left_pr_icon = top_left_2\n",
    "                                self.bottom_right_pr_icon = bottom_right_2\n",
    "\n",
    "                                # black out players remaining icon\n",
    "                                cv.rectangle(top_right_numbers_screenshot, top_left_2, bottom_right_2, color=(0, 0, 0), thickness=-1)\n",
    "                            # no, so go back to the last one we had\n",
    "                            else:\n",
    "                                top_left_2 = self.top_left_pr_icon\n",
    "                                # do we have this?\n",
    "                                if top_left_2 is not None:\n",
    "                                    bottom_right_2 = self.bottom_right_pr_icon\n",
    "                                    # black out players remaining icon\n",
    "                                    cv.rectangle(top_right_numbers_screenshot, top_left_2, bottom_right_2, color=(0, 0, 0), thickness=-1)\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                # bad top left value, crop not as expected\n",
    "                else:\n",
    "                    if self.trusted_top_left is None:\n",
    "                        # no prior success with top_left, forget it\n",
    "                        self.top_left = None\n",
    "                    else:\n",
    "                        # revert to last successful top_left value\n",
    "                        self.top_left = self.trusted_top_left\n",
    "                        top_left = self.top_left\n",
    "                        # correct bottom right and expand left to just grab all linearly alligned numbers at once\n",
    "                        full_bottom_right = (top_left[0] + (needle_w * 2), top_left[1] + needle_h)\n",
    "                        full_top_left = tuple([top_left[0]-125, top_left[1]]) \n",
    "\n",
    "                        # crop full top right numbers bar\n",
    "                        top_right_numbers_screenshot = top_right_numbers_screenshot[full_top_left[1]:full_bottom_right[1], \n",
    "                                                                                    full_top_left[0]:full_bottom_right[0]]\n",
    "            \n",
    "                try:\n",
    "                    # convert opencv back to PIL\n",
    "                    i = Image.fromarray(top_right_numbers_screenshot)\n",
    "\n",
    "                    k_out = f'{self.output_dir}n_kills/{loop}.jpg'\n",
    "                    pr_out = f'{self.output_dir}n_players_remaining/{loop}.jpg'\n",
    "                    crop_out = f'{self.output_dir}crop_screenshot/{loop}.jpg'\n",
    "\n",
    "                    # crop kills & players remaining numbers\n",
    "                    k_crop = i.crop(n_kills_crop)\n",
    "                    pr_crop = i.crop(n_players_remaining_crop)\n",
    "\n",
    "                    # save cropped images (numbers)\n",
    "                    i.save(crop_out)\n",
    "                    k_crop.save(k_out)\n",
    "                    pr_crop.save(pr_out)\n",
    "\n",
    "                    # crop images to (38, 38) from (38, 28)\n",
    "                    k_crop = k_crop.crop((0, 0-5, 38, 28+5))\n",
    "                    pr_crop = pr_crop.crop((0, 0-5, 38, 28+5))\n",
    "\n",
    "                    # make predictions\n",
    "                    try:\n",
    "                        k_pred = self.pull_numbers(np.array(k_crop), model)\n",
    "                        k_pred = ' '.join(k_pred)\n",
    "                        # print(f'n_kills: {k_pred}')\n",
    "                    except Exception as e:\n",
    "                        self.n_pred_errors += 1\n",
    "                        k_pred = None\n",
    "                        print(e)\n",
    "\n",
    "                    try:\n",
    "                        pr_pred = self.pull_numbers(np.array(pr_crop), model)\n",
    "                        pr_pred = ' '.join(pr_pred)\n",
    "                        # print(f'n_plyrs: {pr_pred}')\n",
    "                    except Exception as e:\n",
    "                        self.n_pred_errors += 1\n",
    "                        pr_pred = None\n",
    "                        print(e)\n",
    "\n",
    "                    temp_top_right_numbers_stash.append([pr_pred, k_pred, pr_out, k_out, record_time, \n",
    "                                                         f'{self.output_dir}og_screenshot/{loop}.jpg', self.top_left])   \n",
    "\n",
    "                except Exception as e:\n",
    "                    self.n_save_errors += 1\n",
    "                    print(e)\n",
    "        \n",
    "            if ((_ % 25 == 0) and (len(temp_top_right_numbers_stash) != 0)) or (len(temp_top_right_numbers_stash) > 10):\n",
    "                record_numbers(temp_top_right_numbers_stash, f'{self.output_dir}sample_records.csv')\n",
    "                temp_top_right_numbers_stash = []\n",
    "\n",
    "        record_numbers(temp_top_right_numbers_stash, f'{self.output_dir}sample_records.csv')\n",
    "                \n",
    "    def pull_numbers(self, image, model, knn=True):    \n",
    "        if knn == True:\n",
    "            image = cv.resize(image, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            image = image.reshape(1, -1)  # flatten\n",
    "\n",
    "            numbers = model.predict(image)\n",
    "\n",
    "            return list(numbers)\n",
    "        else:\n",
    "            raise Exception(f'pull_numbers() error | knn != True | knn == {knn}')\n",
    "        \n",
    "    def update_df(self):\n",
    "        \"\"\"\n",
    "        update DataFrame of targets {numbers} and relative file paths {file_path} of labeled images\n",
    "        \"\"\"\n",
    "        dataset_keys = [key for key in self.datasets]\n",
    "        for _ in range(len(dataset_keys)):\n",
    "            if _ == 0:\n",
    "                self.df = pd.read_csv(self.datasets[dataset_keys[_]])\n",
    "            else:\n",
    "                temp_df = pd.read_csv(self.datasets[dataset_keys[_]])\n",
    "                self.df = pd.concat([self.df, temp_df], axis=0) \n",
    "                \n",
    "    def trim_df(self, n, output=False):\n",
    "        \"\"\"\n",
    "        limit number of any label's instances in self.df \n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        for value in df.numbers.unique():\n",
    "            c = len(df.loc[df.numbers==value])\n",
    "            if c > max_label_sample:\n",
    "                temp_df = df.loc[df.numbers == value].sample(max_label_sample)\n",
    "                df = df.loc[df.numbers != value]\n",
    "                df = pd.concat([df, temp_df])\n",
    "            # print(f'{value} | {len(df.loc[df.numbers==value])}')\n",
    "        self.df = df\n",
    "        if output:\n",
    "            return df\n",
    "        \n",
    "    def clear_output_dir(self):\n",
    "        \"\"\"\n",
    "        delete image files and reset CSV in {self.output_dir} & sub directories\n",
    "        \"\"\"\n",
    "        for sub in ['n_kills/', 'n_players_remaining/', 'og_screenshot/', 'crop_screenshot/']:\n",
    "            for f in os.listdir(f'{self.output_dir}{sub}'):\n",
    "                if '.jpg' in f:\n",
    "                    os.remove(f'{self.output_dir}{sub}{f}')\n",
    "        pd.read_csv(f'{self.output_dir}sample_records.csv').head(0).to_csv(f'{self.output_dir}sample_records.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = n.load_image_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = n.train_knn(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.clear_output_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n.record_livestream(model=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.n_save_errors, n.n_pred_errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
